from fastapi import FastAPI, UploadFile, File, Form, Body
from fastapi.responses import JSONResponse
# â¬‡ï¸ [ì¶”ê°€] ë°ì´í„° ëª¨ë¸ë§ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pydantic import BaseModel
from typing import List, Optional
import whisper
import shutil
import os
import re
import traceback
import subprocess
from deep_translator import GoogleTranslator

app = FastAPI()

# ëª¨ë¸ ë¡œë“œ
print("â³ ëª¨ë¸ ë¡œë”© ì¤‘... (Small)")
model = whisper.load_model("small")
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ---------------------------------------------------------
# ğŸ“ [ì¶”ê°€] ë°ì´í„° ëª¨ë¸ ì •ì˜ (ë²ˆì—­ ìš”ì²­ ì‹œ ë°›ì„ ë°ì´í„° êµ¬ì¡°)
# ---------------------------------------------------------
class LyricItem(BaseModel):
    start: float
    text: str
    translated_text: Optional[str] = ""

# ---------------------------------------------------------
# ğŸ› ï¸ [ê¸°ì¡´ ìœ ì§€] FFmpeg ë„êµ¬ ì°¾ê¸°
# ---------------------------------------------------------
def get_ffmpeg_command():
    if shutil.which("ffmpeg"):
        return "ffmpeg"
    current_dir = os.path.dirname(os.path.abspath(__file__))
    local_ffmpeg = os.path.join(current_dir, "ffmpeg.exe")
    if os.path.exists(local_ffmpeg):
        return local_ffmpeg
    raise FileNotFoundError("FFmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------------------------------------------
# ğŸ› ï¸ [ê¸°ì¡´ ìœ ì§€] WAV ë³€í™˜ í•¨ìˆ˜
# ---------------------------------------------------------
def convert_to_clean_wav(input_path):
    try:
        command_executable = get_ffmpeg_command()
        output_path = os.path.splitext(input_path)[0] + "_clean.wav"
        print(f"ğŸ”„ [ë³€í™˜ ì‹œì‘] {input_path} -> {output_path}")
        
        command = [
            command_executable, "-i", input_path, "-ar", "16000", "-ac", "1", 
            "-c:a", "pcm_s16le", "-vn", "-y", output_path
        ]
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return output_path
    except Exception as e:
        print(f"ğŸš¨ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return input_path 

# ---------------------------------------------------------
# ğŸ› ï¸ [ê¸°ì¡´ ìœ ì§€] í™˜ê°(Hallucination) ì œê±° í•¨ìˆ˜
# ---------------------------------------------------------
def clean_hallucinations(segments):
    cleaned = []
    banned_words = ["lyrics", "lyrics.", "ë…¸ë˜ ê°€ì‚¬", "mbc", "subtitles", "sous-titres", "ì‹œì²­í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤"]
    
    for seg in segments:
        text = seg['text'].strip()
        if not text: continue
        if text.lower() in banned_words: continue
        if re.match(r'^[\W_]+$', text): continue
        cleaned.append(seg)
    return cleaned

# ---------------------------------------------------------
# ğŸ› ï¸ [ê¸°ì¡´ ìœ ì§€] LRC íŒŒì‹± & ê°•ì œ ì‹±í¬
# ---------------------------------------------------------
def parse_lrc_with_timestamp(lrc_content: str):
    segments = []
    pattern = re.compile(r'\[?(\d+):(\d+\.?\d*)\]?\s*(.*)')
    for line in lrc_content.splitlines():
        match = pattern.match(line.strip())
        if match:
            minutes, seconds, text = int(match.group(1)), float(match.group(2)), match.group(3).strip()
            if text:
                segments.append({"start": minutes * 60 + seconds, "text": text})
    return segments

def force_align_lyrics(whisper_result, user_text):
    ai_timestamps = [seg['start'] for seg in whisper_result['segments']]
    user_lines = [line.strip() for line in user_text.splitlines() if line.strip()]
    if not ai_timestamps or not user_lines: return []

    final_segments = []
    if not whisper_result['segments']: return [] 

    total_ai_duration = whisper_result['segments'][-1]['end'] - whisper_result['segments'][0]['start']
    start_offset = whisper_result['segments'][0]['start']
    
    for i, line in enumerate(user_lines):
        percent = i / len(user_lines)
        calculated_time = round(start_offset + (total_ai_duration * percent), 2)
        final_segments.append({"start": calculated_time, "text": line})
    return final_segments

# ---------------------------------------------------------
# ğŸŒ [ìˆ˜ì •] ë²ˆì—­ ì‹¤í–‰ í•¨ìˆ˜ (ë…ë¦½ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë³€ê²½)
# ---------------------------------------------------------
def perform_translation(segments, target_lang='ko'):
    print("ğŸŒ [ë²ˆì—­ ì‹¤í–‰] Google Translate...")
    translator = GoogleTranslator(source='auto', target=target_lang)
    
    for seg in segments:
        try:
            # ë”•ì…”ë„ˆë¦¬ì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸í•˜ì—¬ ì²˜ë¦¬
            original = seg['text'] if isinstance(seg, dict) else seg.text
            
            translated = translator.translate(original)
            
            if isinstance(seg, dict):
                seg['translated_text'] = translated
            else:
                seg.translated_text = translated
        except Exception as e:
            print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨ (ë¶€ë¶„): {e}")
            if isinstance(seg, dict):
                seg['translated_text'] = ""
            else:
                seg.translated_text = ""
            
    print("âœ… [ë²ˆì—­ ì™„ë£Œ]")
    return segments

# =========================================================
# ğŸš€ API 1: ì˜¤ë””ì˜¤ ë¶„ì„ (ë²ˆì—­ ê¸°ëŠ¥ ì œê±°ë¨)
# =========================================================
@app.post("/analyze")
async def analyze_audio(
    file: UploadFile = File(...), 
    language: str = Form("auto"), 
    lyrics_text: str = Form(None)
):
    temp_filename = f"temp_{file.filename}"
    clean_audio_path = None
    actual_language = None if language == "auto" else language

    print(f"\nğŸš€ [ë¶„ì„ ìš”ì²­] {file.filename} / ì–¸ì–´: {actual_language if actual_language else 'ìë™'}")

    try:
        # 1. ì›ë³¸ ì €ì¥ ë° ë³€í™˜
        with open(temp_filename, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        clean_audio_path = convert_to_clean_wav(temp_filename)

        final_result = []

        # A. ì‚¬ìš©ì ê°€ì‚¬ ìˆìŒ
        if lyrics_text:
            print(f"ğŸ“ ì‚¬ìš©ì ê°€ì‚¬ ìˆ˜ì‹ ë¨")
            parsed = parse_lrc_with_timestamp(lyrics_text)
            if len(parsed) > 0:
                print("âœ¨ ì‹œê°„ ì •ë³´ í¬í•¨ë¨ -> ë°”ë¡œ ì ìš©")
                final_result = parsed
            else:
                print("ğŸ’¡ í…ìŠ¤íŠ¸ë§Œ ìˆìŒ -> AIë¡œ ì‹œê°„ ì¶”ì¶œ")
                raw_result = model.transcribe(clean_audio_path, language=actual_language, fp16=False)
                final_result = force_align_lyrics(raw_result, lyrics_text)
        
        # B. ê°€ì‚¬ ì—†ìŒ (AI ë°›ì•„ì“°ê¸°)
        else:
            print(f"ğŸ¤– ê°€ì‚¬ ì—†ìŒ -> AI ë°›ì•„ì“°ê¸° ëª¨ë“œ")
            result = model.transcribe(
                clean_audio_path, 
                language=actual_language,
                initial_prompt="Hello, this is a song.", 
                fp16=False,
                condition_on_previous_text=False, 
                no_speech_threshold=0.6, 
                logprob_threshold=-1.0 
            )
            final_result = clean_hallucinations(result['segments'])

        # âš ï¸ ì¤‘ìš”: ì—¬ê¸°ì„œëŠ” ë²ˆì—­ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ê²°ê³¼ë§Œ ë¦¬í„´í•©ë‹ˆë‹¤!
        
        # íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_filename): os.remove(temp_filename)
        if clean_audio_path != temp_filename and os.path.exists(clean_audio_path): 
            os.remove(clean_audio_path)
            
        return JSONResponse(content={"segments": final_result})

    except Exception as e:
        print(f"\nğŸ’¥ ì—ëŸ¬ ë°œìƒ: {traceback.format_exc()}")
        if os.path.exists(temp_filename): os.remove(temp_filename)
        if clean_audio_path and clean_audio_path != temp_filename and os.path.exists(clean_audio_path): 
            os.remove(clean_audio_path)
        return JSONResponse(content={"error": str(e)}, status_code=500)

# =========================================================
# ğŸš€ API 2: ë²ˆì—­ ì „ìš© (ë²„íŠ¼ ëˆ„ë¥´ë©´ í˜¸ì¶œë¨) [ì‹ ê·œ ì¶”ê°€]
# =========================================================
@app.post("/translate")
async def translate_lyrics(lyrics: List[LyricItem]):
    print(f"\nğŸŒ [ë²ˆì—­ ìš”ì²­] ì´ {len(lyrics)}ì¤„ ë²ˆì—­ ì‹œì‘")
    
    try:
        # Pydantic ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        dict_lyrics = [item.dict() for item in lyrics]
        
        # ë²ˆì—­ ìˆ˜í–‰
        translated_result = perform_translation(dict_lyrics)
        
        return JSONResponse(content={"segments": translated_result})
        
    except Exception as e:
        print(f"ğŸ’¥ ë²ˆì—­ ì—ëŸ¬: {traceback.format_exc()}")
        return JSONResponse(content={"error": str(e)}, status_code=500)